{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KDAvBfA40xvC"
      },
      "outputs": [],
      "source": [
        "import torch  # PyTorch library for deep learning\n",
        "import torch.nn as nn  # For neural network functionalities\n",
        "import numpy as np  # For numerical operations\n",
        "from unet import UNet  # U-Net model\n",
        "from cnn import CNN  # Custom CNN model\n",
        "import matplotlib.pyplot as plt  # For plotting\n",
        "import torchvision.ops as ops  # For image processing operations\n",
        "import cv2 as cv  # OpenCV library for image manipulation\n",
        "import os  # For interacting with the file system\n",
        "import csv  # For writing CSV files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3FemjcEi053r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU (cuda) for faster processing if available\n",
        "torch.cuda.set_device(0)\n",
        "device = torch.device('cuda')  # Ensures using GPU"
      ],
      "metadata": {
        "id": "EfGSRoTc06u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir(directory):\n",
        "    # Read each image\n",
        "    img = cv.imread(os.path.join(directory, file))\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)  # Convert from BGR to RGB color format\n",
        "    img = cv.resize(img, (224, 224))  # Resize the image to 224x224\n",
        "    images.append(img)  # Append the image to the list"
      ],
      "metadata": {
        "id": "3oWxCxKT06wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crop images based on mask bounding boxes\n",
        "cropped_images = []\n",
        "for i in range(images.shape[0]):\n",
        "    # Convert the mask to bounding boxes and crop the images\n",
        "    points = ops.masks_to_boxes(masks[i].unsqueeze(0)).int().tolist()[0]  # Get bounding box coordinates\n",
        "    img = images[i][points[1]:points[3], points[0]:points[2]]  # Crop image using bounding box\n",
        "    img = cv.resize(img.numpy(), (64, 64))  # Resize image to 64x64\n",
        "    cropped_images.append(img)  # Append cropped image to the list"
      ],
      "metadata": {
        "id": "tFfvHji706yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize image pixels (RGB channels are normalized with mean and std)\n",
        "images = np.stack(images) / 255  # Stack images into a numpy array and scale pixel values"
      ],
      "metadata": {
        "id": "__xyaRxS060R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the image array into R, G, and B channels\n",
        "r = images[:, :, :, 0]\n",
        "g = images[:, :, :, 1]\n",
        "b = images[:, :, :, 2]"
      ],
      "metadata": {
        "id": "ocCjmh3j062K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize each channel using ImageNet's pre-trained values\n",
        "r = (r - 0.485) / 0.229  # Normalize Red channel\n",
        "g = (g - 0.456) / 0.224  # Normalize Green channel\n",
        "b = (b - 0.406) / 0.225  # Normalize Blue channel"
      ],
      "metadata": {
        "id": "jwWHmDkQ0639"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack the normalized channels back together\n",
        "images = np.stack([r, g, b], axis=3)"
      ],
      "metadata": {
        "id": "s12QV2Uc065q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained CNN model\n",
        "cnn = CNN()  # Instantiate the CNN model\n",
        "cnn.load_state_dict(torch.load(\"models/cnn.pt\", weights_only=True))  # Load pre-trained weights\n",
        "cnn.to(device)  # Move the model to the GPU\n",
        "cnn.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "id": "5G3th1F_069P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the test dataset\n",
        "test_set = torch.tensor(images, dtype=torch.float32)  # Convert images to a PyTorch tensor\n",
        "predictions = []  # List to store predicted labels"
      ],
      "metadata": {
        "id": "Nl6QzX_306-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the test set and make predictions\n",
        "for i in range(test_set.shape[0]):\n",
        "    t = test_set[i:i+1].to(device)  # Get one image and move it to the GPU\n",
        "    l = cnn(t.permute(0, 3, 1, 2))  # Permute the dimensions of the image (from HWC to CHW)\n",
        "    predictions.append(torch.argmax(torch.softmax(l, dim=1)).item() + 1)  # Get the predicted class index (add 1 for 1-based indexing)"
      ],
      "metadata": {
        "id": "Z6uaAW3507A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the predictions to be written into a CSV file\n",
        "files = os.listdir(\"test\")  # List of filenames in the 'test' directory\n",
        "dictionary = []  # List to store the file names and corresponding predictions\n",
        "for i in range(len(files)):\n",
        "    dictionary.append([files[i], predictions[i]])  # Append the file name and prediction to the list"
      ],
      "metadata": {
        "id": "wUiJT-HG07Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the predictions to a CSV file for submission\n",
        "with open(\"submission.csv\", mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)  # Create a CSV writer object\n",
        "    writer.writerows(dictionary)  # Write the rows to the CSV file"
      ],
      "metadata": {
        "id": "sEB-4N1707Eo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}