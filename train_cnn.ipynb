{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "KDAvBfA40xvC",
        "outputId": "0cd248b9-66a1-4452-9dd4-2ac2ca0aea9c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cnn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5b49f1ce5a31>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m  \u001b[0;31m# For pre-trained models (not used here but imported)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mops\u001b[0m  \u001b[0;31m# For image operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCNN\u001b[0m  \u001b[0;31m# Assuming CNN is a custom class from another file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cnn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import cv2 as cv  # OpenCV for image processing\n",
        "import os  # For directory and file manipulation\n",
        "import numpy as np  # For numerical operations\n",
        "import matplotlib.pyplot as plt  # For plotting loss curves\n",
        "import torch  # For PyTorch framework\n",
        "from torch import nn  # For neural network modules\n",
        "import torch.nn.functional as F  # For utility functions\n",
        "import torchvision.models as models  # For pre-trained models\n",
        "import torchvision.ops as ops  # For image operations\n",
        "from cnn import CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3FemjcEi053r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU (cuda)\n",
        "torch.cuda.set_device(0)\n",
        "device = torch.device('cuda')  # Use the GPU if available\n",
        "loss_function = nn.CrossEntropyLoss()  # Cross entropy loss function for classification"
      ],
      "metadata": {
        "id": "EfGSRoTc06u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the masks and images data\n",
        "masks = torch.tensor(np.load(\"masks.npy\"))  # Masks array loaded\n",
        "images = torch.tensor(np.load(\"images.npy\"))  # Images array loaded"
      ],
      "metadata": {
        "id": "3oWxCxKT06wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crop images based on mask bounding boxes\n",
        "cropped_images = []\n",
        "for i in range(images.shape[0]):\n",
        "    # Convert the mask to bounding boxes and crop the images\n",
        "    points = ops.masks_to_boxes(masks[i].unsqueeze(0)).int().tolist()[0]  # Get bounding box coordinates\n",
        "    img = images[i][points[1]:points[3], points[0]:points[2]]  # Crop image using bounding box\n",
        "    img = cv.resize(img.numpy(), (64, 64))  # Resize image to 64x64\n",
        "    cropped_images.append(img)  # Append cropped image to the list"
      ],
      "metadata": {
        "id": "tFfvHji706yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack cropped images into a single tensor\n",
        "images = np.stack(cropped_images)"
      ],
      "metadata": {
        "id": "__xyaRxS060R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels from directory structure\n",
        "labels = []\n",
        "directory = \"train\\\\\"  # Path to training images\n",
        "for folder in os.listdir(directory):\n",
        "    inner_directory = os.path.join(directory, folder)  # Inner folder (class directories)\n",
        "    for file in os.listdir(inner_directory):\n",
        "        # Append the label multiple times (likely to account for class repetitions)\n",
        "        labels.append(int(folder))\n",
        "        labels.append(int(folder))\n",
        "        labels.append(int(folder))\n",
        "        labels.append(int(folder))"
      ],
      "metadata": {
        "id": "ocCjmh3j062K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list of labels to a tensor\n",
        "labels = np.stack(labels)"
      ],
      "metadata": {
        "id": "jwWHmDkQ0639"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert images and labels to PyTorch tensors\n",
        "images = torch.tensor(images, dtype=torch.float32)\n",
        "labels = torch.tensor(labels, dtype=torch.long) - 1  # Subtract 1 to adjust labels to 0-based indexing"
      ],
      "metadata": {
        "id": "s12QV2Uc065q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data (80:20 for training and validation, but using 100:0 for training in this case)\n",
        "split = int(images.shape[0]*1)  # Full dataset used for training\n",
        "train_images = images[:split]\n",
        "train_labels = labels[:split]\n",
        "val_images = images[split:]\n",
        "val_labels = labels[split:]"
      ],
      "metadata": {
        "id": "5G3th1F_069P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shapes of training and validation labels\n",
        "print(train_labels.shape)\n",
        "print(val_labels.shape)"
      ],
      "metadata": {
        "id": "Nl6QzX_306-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the CNN model and optimizer\n",
        "model = CNN()  # Custom CNN model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Adam optimizer\n",
        "model.to(device)  # Move model to GPU"
      ],
      "metadata": {
        "id": "Z6uaAW3507A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation function to calculate loss on the validation set\n",
        "def val_loss():\n",
        "    val_losses = []  # List to store loss for each validation sample\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    for i in range(val_images.shape[0]):\n",
        "        # Get a single validation sample\n",
        "        x = val_images[i:i+1]\n",
        "        y = val_labels[i:i+1]\n",
        "\n",
        "        # Move data to GPU\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(x.permute(0, 3, 1, 2))  # Rearrange image dimensions for PyTorch model\n",
        "        loss = loss_function(logits, y)  # Compute loss\n",
        "        val_losses.append(loss.item())  # Append loss to list\n",
        "    model.train()  # Set the model back to training mode\n",
        "    return sum(val_losses) / len(val_losses)  # Return the average validation loss"
      ],
      "metadata": {
        "id": "wUiJT-HG07Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the model\n",
        "n_epochs = 50  # Number of training epochs\n",
        "batch_size = 16  # Batch size"
      ],
      "metadata": {
        "id": "sEB-4N1707Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []  # List to store training loss values\n",
        "for epoch in range(n_epochs):\n",
        "    permutation = torch.randperm(train_images.shape[0])  # Shuffle training data\n",
        "    for i in range(0, permutation.shape[0], batch_size):\n",
        "        optimizer.zero_grad()  # Clear gradients from previous iteration\n",
        "\n",
        "        indices = permutation[i:i+batch_size]  # Select batch indices\n",
        "        x, y = train_images[indices], train_labels[indices]  # Get batch data\n",
        "\n",
        "        # Move data to GPU\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(x.permute(0, 3, 1, 2))  # Rearrange image dimensions\n",
        "        loss = loss_function(logits, y)  # Compute loss\n",
        "        losses.append(loss.item())  # Store loss value\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()  # Update model weights"
      ],
      "metadata": {
        "id": "Z_9TDn0t07Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training losses over time\n",
        "plt.plot(losses)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qFtMdXuK07LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation on the validation set\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "val_losses = []  # List to store validation losses\n",
        "for i in range(val_images.shape[0]):\n",
        "    x = val_images[i:i+1]\n",
        "    y = val_labels[i:i+1]\n",
        "\n",
        "    # Move data to GPU\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    logits = model(x.permute(0, 3, 1, 2))  # Rearrange image dimensions\n",
        "    loss = loss_function(logits, y)  # Compute loss\n",
        "    val_losses.append(loss.item())  # Append loss to list"
      ],
      "metadata": {
        "id": "jUsj5D6p07Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print average validation loss\n",
        "print(f'Validation Loss: {sum(val_losses) / len(val_losses)}')"
      ],
      "metadata": {
        "id": "qhhGz7gt07O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"models/cnn.pt\")"
      ],
      "metadata": {
        "id": "_SW5IQSV07Qm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}