{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbBkCTN3KP2i"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv  # OpenCV for image processing\n",
        "import os  # For directory and file manipulation\n",
        "import numpy as np  # For numerical operations\n",
        "import matplotlib.pyplot as plt  # For plotting loss curves\n",
        "import torch  # For PyTorch framework\n",
        "from torch import nn  # For neural network modules\n",
        "import torch.nn.functional as F  # For utility functions\n",
        "import torchvision.models as models  # For pre-trained models\n",
        "import torchvision.ops as ops  # For image operations\n",
        "from cnn import CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU (cuda)\n",
        "torch.cuda.set_device(0)\n",
        "device = torch.device('cuda')  # Use the GPU if available\n",
        "loss_function = nn.CrossEntropyLoss()  # Cross entropy loss function for classification"
      ],
      "metadata": {
        "id": "ezYGJAodKSzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the masks and images data\n",
        "masks = torch.tensor(np.load(\"masks.npy\"))  # Masks array loaded\n",
        "images = torch.tensor(np.load(\"images.npy\"))  # Images array loaded"
      ],
      "metadata": {
        "id": "Fwyc1DpAKS2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crop images based on mask bounding boxes\n",
        "cropped_images = []\n",
        "for i in range(images.shape[0]):\n",
        "    # Convert the mask to bounding boxes and crop the images\n",
        "    points = ops.masks_to_boxes(masks[i].unsqueeze(0)).int().tolist()[0]  # Get bounding box coordinates\n",
        "    img = images[i][points[1]:points[3], points[0]:points[2]]  # Crop image using bounding box\n",
        "    img = cv.resize(img.numpy(), (64, 64))  # Resize image to 64x64\n",
        "    cropped_images.append(img)  # Append cropped image to the list"
      ],
      "metadata": {
        "id": "fkZkX9ULKS4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack cropped images into a single tensor\n",
        "images = np.stack(cropped_images)"
      ],
      "metadata": {
        "id": "8BSSlWkrKS6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels from directory structure\n",
        "labels = []\n",
        "directory = \"train\\\"  # Path to training images\n",
        "for folder in os.listdir(directory):\n",
        "    inner_directory = os.path.join(directory, folder)  # Inner folder (class directories)\n",
        "    for file in os.listdir(inner_directory):\n",
        "        # Append the label multiple times (likely to account for class repetitions)\n",
        "        labels.append(int(folder))\n",
        "        labels.append(int(folder))\n",
        "        labels.append(int(folder))\n",
        "        labels.append(int(folder))"
      ],
      "metadata": {
        "id": "jnj-X4JwKS8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list of labels to a tensor\n",
        "labels = np.stack(labels)"
      ],
      "metadata": {
        "id": "8JA7JuI-KS94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert images and labels to PyTorch tensors\n",
        "images = torch.tensor(images, dtype=torch.float32)\n",
        "labels = torch.tensor(labels, dtype=torch.long) - 1  # Subtract 1 to adjust labels to 0-based indexing"
      ],
      "metadata": {
        "id": "Id1ZHtLlKS_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data (80:20 for training and validation, but using 100:0 for training in this case)\n",
        "split = int(images.shape[0]*1)  # Full dataset used for training\n",
        "train_images = images[:split]\n",
        "train_labels = labels[:split]\n",
        "val_images = images[split:]\n",
        "val_labels = labels[split:]"
      ],
      "metadata": {
        "id": "5uUCnxkpKTBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shapes of training and validation labels\n",
        "print(train_labels.shape)\n",
        "print(val_labels.shape)"
      ],
      "metadata": {
        "id": "mhm_41LbKTDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the CNN model and optimizer\n",
        "model = CNN()  # Custom CNN model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Adam optimizer\n",
        "model.to(device)  # Move model to GPU"
      ],
      "metadata": {
        "id": "XZeEDc5lKTFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation function to calculate loss on the validation set\n",
        "def val_loss():\n",
        "    val_losses = []  # List to store loss for each validation sample\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    for i in range(val_images.shape[0]):\n",
        "        # Get a single validation sample\n",
        "        x = val_images[i:i+1]\n",
        "        y = val_labels[i:i+1]\n",
        "\n",
        "        # Move data to GPU\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(x.permute(0, 3, 1, 2))  # Rearrange image dimensions for PyTorch model\n",
        "        loss = loss_function(logits, y)  # Compute loss\n",
        "        val_losses.append(loss.item())  # Append loss to list\n",
        "    model.train()  # Set the model back to training mode\n",
        "    return sum(val_losses) / len(val_losses)  # Return the average validation loss"
      ],
      "metadata": {
        "id": "Yq3twQFBKTG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the model\n",
        "n_epochs = 50  # Number of training epochs\n",
        "batch_size = 16  # Batch size"
      ],
      "metadata": {
        "id": "LD9fKrPMKTIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []  # List to store training loss values\n",
        "for epoch in range(n_epochs):\n",
        "    permutation = torch.randperm(train_images.shape[0])  # Shuffle training data\n",
        "    for i in range(0, permutation.shape[0], batch_size):\n",
        "        optimizer.zero_grad()  # Clear gradients from previous iteration\n",
        "\n",
        "        indices = permutation[i:i+batch_size]  # Select batch indices\n",
        "        x, y = train_images[indices], train_labels[indices]  # Get batch data\n",
        "\n",
        "        # Move data to GPU\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(x.permute(0, 3, 1, 2))  # Rearrange image dimensions\n",
        "        loss = loss_function(logits, y)  # Compute loss\n",
        "        losses.append(loss.item())  # Store loss value\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()  # Update model weights"
      ],
      "metadata": {
        "id": "d7liDM1QKTKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training losses over time\n",
        "plt.plot(losses)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kwpekgggKTMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation on the validation set\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "val_losses = []  # List to store validation losses\n",
        "for i in range(val_images.shape[0]):\n",
        "    x = val_images[i:i+1]\n",
        "    y = val_labels[i:i+1]\n",
        "\n",
        "    # Move data to GPU\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    logits = model(x.permute(0, 3, 1, 2))  # Rearrange image dimensions\n",
        "    loss = loss_function(logits, y)  # Compute loss\n",
        "    val_losses.append(loss.item())  # Append loss to list"
      ],
      "metadata": {
        "id": "E3cYbMbcKTN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print average validation loss\n",
        "print(f'Validation Loss: {sum(val_losses) / len(val_losses)}')"
      ],
      "metadata": {
        "id": "FNNzl858KTPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"models/cnn.pt\")"
      ],
      "metadata": {
        "id": "qMc16NzvKTRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}