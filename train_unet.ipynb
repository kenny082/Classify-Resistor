{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KDAvBfA40xvC"
      },
      "outputs": [],
      "source": [
        "import torch  # PyTorch library for deep learning\n",
        "import torch.nn as nn  # For neural network functionality\n",
        "import numpy as np  # For numerical operations (arrays)\n",
        "from unet import UNet  # Import the UNet model (assumed to be defined elsewhere)\n",
        "import matplotlib.pyplot as plt  # For plotting loss curves\n",
        "import torchvision.ops as ops  # For image processing operations (though not used here)\n",
        "import cv2 as cv  # OpenCV library for image processing\n",
        "import os  # For interacting with the file system (directories, files)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3FemjcEi053r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU (cuda) for faster processing if available\n",
        "torch.cuda.set_device(0)  # Set GPU device (if available)\n",
        "device = torch.device('cuda')  # Move computation to the GPU\n",
        "loss_function = nn.BCEWithLogitsLoss()  # Binary Cross Entropy loss with logits for segmentation"
      ],
      "metadata": {
        "id": "EfGSRoTc06u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess images from the 'train' directory\n",
        "images = []\n",
        "directory = \"train\\\\\"  # Directory where the training images are stored"
      ],
      "metadata": {
        "id": "3oWxCxKT06wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to [0, 1] range\n",
        "images = np.stack(images) / 255  # Stack images into a numpy array"
      ],
      "metadata": {
        "id": "tFfvHji706yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize image pixels (RGB channels are normalized with mean and std)\n",
        "images = np.stack(images) / 255  # Stack images into a numpy array and scale pixel values"
      ],
      "metadata": {
        "id": "__xyaRxS060R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the RGB channels and normalize them based on ImageNet statistics\n",
        "r = images[:, :, :, 0]\n",
        "g = images[:, :, :, 1]\n",
        "b = images[:, :, :, 2]"
      ],
      "metadata": {
        "id": "ocCjmh3j062K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize each channel (using ImageNet's statistics)\n",
        "r = (r - 0.485) / 0.229\n",
        "g = (g - 0.456) / 0.224\n",
        "b = (b - 0.406) / 0.225"
      ],
      "metadata": {
        "id": "jwWHmDkQ0639"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack the normalized channels back together\n",
        "images = np.stack([r, g, b], axis=3)"
      ],
      "metadata": {
        "id": "s12QV2Uc065q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the preprocessed images to disk for later use\n",
        "np.save(\"images.npy\", images)"
      ],
      "metadata": {
        "id": "5G3th1F_069P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the masks (binary segmentation labels)\n",
        "masks = []\n",
        "directory = \"masks\\\\\"  # Directory where mask files are stored"
      ],
      "metadata": {
        "id": "Nl6QzX_306-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir(directory):\n",
        "    inner_directory = os.path.join(directory, folder)\n",
        "    for file in os.listdir(inner_directory):\n",
        "        # Load mask from file (assuming numpy format for masks)\n",
        "        img = np.load(os.path.join(inner_directory, file))\n",
        "\n",
        "        # Augment the masks by rotating them in various orientations (same as images)\n",
        "        masks.append(np.rot90(img, 0))  # No rotation\n",
        "        masks.append(np.rot90(img, 1, axes=(1, 0)))  # 90° rotation\n",
        "        masks.append(np.rot90(img, 1, axes=(0, 1)))  # 90° rotation in another direction\n",
        "        masks.append(np.rot90(img, 2))  # 180° rotation"
      ],
      "metadata": {
        "id": "Z6uaAW3507A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack the masks into a numpy array\n",
        "masks = np.stack(masks)"
      ],
      "metadata": {
        "id": "wUiJT-HG07Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the masks to ensure they are loaded correctly\n",
        "print(masks.shape)"
      ],
      "metadata": {
        "id": "sEB-4N1707Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the processed masks to disk\n",
        "np.save(\"masks.npy\", masks)"
      ],
      "metadata": {
        "id": "NAwC7sC_C3d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the images and masks to PyTorch tensors\n",
        "images = torch.tensor(np.load(\"images.npy\"), dtype=torch.float32)\n",
        "masks = torch.tensor(np.load(\"masks.npy\"), dtype=torch.float32)"
      ],
      "metadata": {
        "id": "k9u4E0KIC3i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets\n",
        "split = int(images.shape[0] * 1)  # Use all data for training (no validation in this case)\n",
        "train_images = images[:split]\n",
        "train_masks = masks[:split]"
      ],
      "metadata": {
        "id": "XCG7VWksC5Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = images[split:]\n",
        "val_masks = masks[split:]"
      ],
      "metadata": {
        "id": "cisamPB8C525"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shapes of the training and validation sets\n",
        "print(train_masks.shape)\n",
        "print(val_masks.shape)"
      ],
      "metadata": {
        "id": "YYTlp851C543"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the validation loss\n",
        "def val_loss():\n",
        "    val_losses = []\n",
        "    for i in range(val_images.shape[0]):\n",
        "        # Calculate the loss for each image in the validation set\n",
        "        val_losses.append(\n",
        "            loss_function(\n",
        "                model(val_images[i:i+1].permute(0, 3, 1, 2).to(device)).squeeze(),\n",
        "                val_masks[i:i+1].to(device).squeeze()\n",
        "            ).item()\n",
        "        )\n",
        "    return sum(val_losses) / len(val_losses)"
      ],
      "metadata": {
        "id": "-9-OgMjhC3nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables for tracking losses\n",
        "losses = []  # List to store training losses\n",
        "val_losses = []  # List to store validation losses (currently not used)"
      ],
      "metadata": {
        "id": "0R2ydBq5DUig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "n_epochs = 100  # Number of training epochs\n",
        "batch_size = 16  # Batch size for training"
      ],
      "metadata": {
        "id": "iSs3sh-LDV9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(n_epochs):\n",
        "    permutation = torch.randperm(train_images.shape[0])  # Shuffle the training data\n",
        "    for i in range(0, permutation.shape[0], batch_size):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get the batch of images and masks\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        x, y = train_images[indices], train_masks[indices]\n",
        "\n",
        "        x = x.to(device)  # Move the images to the GPU\n",
        "        y = y.to(device)  # Move the masks to the GPU\n",
        "\n",
        "        # Forward pass: pass the images through the model\n",
        "        logits = model(x.permute(0, 3, 1, 2))  # Permute the input dimensions for PyTorch CNN\n",
        "        loss = loss_function(logits.squeeze(), y.squeeze())  # Calculate the loss\n",
        "        losses.append(loss.item())  # Append the loss to the list\n",
        "\n",
        "        # Backward pass: compute gradients and update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "XIJrl8dPDV_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training loss curve\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "n06GY4hADWBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model parameters to disk\n",
        "torch.save(model.state_dict(), \"models/unet.pt\")"
      ],
      "metadata": {
        "id": "QFLN1rocDUmF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
